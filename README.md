# Getting started with Sinara ML

## Prerequisites

- Docker is up and running
- Git installed
- Unzip installed (On Linux and MacOS)

## Prepare docker with WSL integration on a Windows machine (skip this step if you running on MacOS or Linux)
1. Download and install latest docker desktop from https://www.docker.com/products/docker-desktop
1. Setup WSL using guide at https://learn.microsoft.com/en-us/windows/wsl/install-manual
1. If you are using PowerShell scripts, make sure Execution Policy is set to RemoteSigned using PowerShell console in Administrator mode:
```
 Set-ExecutionPolicy RemoteSigned
```

## Setup Sinara ML on your desktop

```
git clone --recursive https://github.com/4-DS/sinara-ext-tools.git
cd sinara-ext-tools
```

To run Sinara ML make the following:<br>
Linux and MacOS:<br>
```
bash create.sh
bash run.sh
```
Windows (PowerShell):<br>
```
.\create.ps1
.\run.ps1
```
Open Jupyter Notebook Server at http://127.0.0.1:8888/lab in any browser.<br>
Inside Jupyter server terminal run:<br>
```
git clone --recursive https://github.com/4-DS/step_template.git
cd step_template
```

Run 'Init_Data.ipynb' to get sample data

Run 'step.dev.py' in Jupyter server terminal: 

```
python step.dev.py
```

To stop Sinara ML instance, execute:<br>
Inside sinara-ext-tools folder<br>
Linux and MacOS:<br>
```
bash stop.sh
```
Windows (PowerShell):<br>
```
.\stop.ps1
```
To continue using the Sinara ML instance, execute:<br>
Linux and MacOS:<br>
```
bash run.sh
```
Windows (PowerShell):<br>
```
.\run.ps1
```
To remove the Sinara ML instance, execute:<br>
Linux and MacOS:<br>
```
bash remove.sh
```
Windows (PowerShell):<br>
```
.\remove.ps1
```
# Notes on creating and removing Sinara ML
These commands creates docker volumes for data, code and temporary data. For day to day usage we recommend using folder mapping on local disk.

# Pipeline qui—Åk conceptual intro
Our framework allows you to create and visualize ML pipelines. They consist of steps. Another word, each element of the DAG is a step. At the output and at the input of each step we have entities. An entity is a dataset that is saved in the file system folder as a parquet file. Each step (component) of the pipeline is implemented as a separate Git repository. Each step is created based on a template.

ML pipeline example is shown at the picture below:

![the picture](examples/example.png)

Each step is implemented as a sequence of substeps (Jupyter notebooks). Each Jupyter notebook that implements the substep contains 2 special cells at the beginning: 
1. a cell with parameters;
2. a cell with an interface. 

And the interface is a description of the inputs and outputs (entities).

# ML pipeline tutorial

To implement the pipeline in the picture above, please follow these steps:

1. Open Jupyter Notebook Server at http://127.0.0.1:8888/lab in any browser<br>
2. Clone Sinara internal tools repo:
```
git clone https://github.com/4-DS/sinara-int-tools.git
```
3. Automatically create your pipeline structure in GitHub with as many steps as you want.
```
bash create_pipeline.sh
``` 
4. Go to steps folders and define interfaces:

![the picture](examples/define_interfaces.png)

5. Define a step name for each repository:

![the picture](examples/define_step_name.png)

6. Build design of your ML pipeline:<br>
Open ```visualize.ipynb``` notebook and replace an example step folder glob inside visualize() function call to your actual steps folder glob<br>
Run ```visualize.ipynb``` notebook

Also, you can try a ready example:

1. Clone the ready repos:
```
git clone --recursive https://github.com/4-DS/pipeline-step1.git
git clone --recursive https://github.com/4-DS/pipeline-step2.git
git clone --recursive https://github.com/4-DS/pipeline-step3.git
git clone --recursive https://github.com/4-DS/pipeline-step4.git
```

2. Open ```visualize.ipynb``` from sinara-int-tools repository
3. Change glob path in visualize() to the folder where steps are cloned
4. Run the notebook cells

# Model serving intro

Now we know how to implement an abstract ML pipeline, but we need more:
at the output, we need to get a model packaged in a Docker container and being accessible via the REST interface. Sinara framework allows you to save a bentoservice as an output entity. In fact, bentoservice is a Python class wrapper for packaging a model with a REST interface. Additionally, Sinara framework provides a contenraize tool to create a Docker image based on a bentoservice. As a result, the name of the image is such that you can then understand from which bentoservice it was created.

# Model serving tutorial
### Open Jupyter Notebook Server at http://127.0.0.1:8888/lab in any browser
Inside Jupyter server terminal run:<br>
1. Clone the ready model (a step of your pipeline):
```
git clone --recursive https://github.com/4-DS/pipeline-model_train.git
```

2. Create bentoservice entity from your model:
```
cd pipeline-model_train
python step.dev.py
```

3. Pick up the entity path for your model packed as a bentoservice entity:

![the picture](examples/get_bentoservice_path.png)

4. Run a containerize tool from sinara-ext-tools (cloned earler on the host) for getting Docker image of your model. Set run parameters at prompt:<br>
  
Linux and MacOS:<br>
```
bash containerize.sh
```
Windows (Powershell):
```
.\containerize.ps1
```

Now you can use your model in production. Docker image will be automatically versioned as:

```<your_docker_registry>/<env>.<pipeline>.<zone>.<step>:<step_run_id>```

# Full conceptual overview

To be continued..
